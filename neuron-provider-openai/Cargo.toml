[package]
name = "neuron-provider-openai"
version = "0.1.0"
edition.workspace = true
rust-version.workspace = true
description = "OpenAI Chat Completions API client for Rust â€” streaming, tool use, and structured output. Compatible with Azure, Groq, and OpenAI-compatible endpoints. Part of neuron."
license.workspace = true
repository.workspace = true
homepage.workspace = true
documentation = "https://docs.rs/neuron-provider-openai"
keywords = ["ai", "llm", "openai", "gpt", "streaming"]
categories = ["artificial-intelligence", "api-bindings"]
exclude = ["CLAUDE.md"]

[dependencies]
neuron-types.workspace = true
reqwest.workspace = true
serde.workspace = true
serde_json.workspace = true
futures.workspace = true
tracing.workspace = true
tokio.workspace = true
async-stream.workspace = true
bytes.workspace = true

[dev-dependencies]
tokio = { workspace = true, features = ["macros", "rt-multi-thread"] }
wiremock.workspace = true
